# Machine Learning System Design (Educative course) - Part 2
## Feed Ranking

**Problem Statement**

Design a personalized LinkedIn feed to maximize long-term user engagement (example: user frequency, Click Through Rate). LI feed contains connections, informational, profile, opinion, site-specific. Different activities have very different CTR

**Metrics**

Offline metrics
- Click Through Rate (CTR) = number of clicks that feed receives, divided by the number of times the feed is shown
- Normalize cross-entropy and AUC
Online metrics
- Conversion rate (ratio of clicks with number of feeds)

**Requirements**

Training
- retrain the models (incrementally) multiple times per day
- personalization - different users have different tastes and styles for consuming their feed
- data freshness - avoid showing repetitive feed for user

Inference
- scalability - handle 300m users)
- latency - return within 50ms
- data freshness - Feed Ranking needs to be fully aware of whether or not a user has already seen any particular activity. Data pipelines need to run really fast

**Modeling**

Feature engineering:
- user profile (job title, industry, demographic, etc.) —> low cardinality then one-hot encoding else Embedding
- Connection strength between users —> similarity between users or Embedding for users and measure the distance vector
- Activity features —> activity Embedding and measure the similarity between activity and user
- Cross features —>  combine multiple features


Training data:
- select a period of data: last month, last 6 months, etc. (balance training time and model accuracy)
- downsample the negative data to handle the imbalanced data
- ways to collect training data:
    - rank by chronicle order - rank post based on chronological order to collect click/not-click data (serving bias because of user’s attention on the first few posts)
    - random serving - rank post by random order (may lead to bad UX)
    - feed ranking algorithm - ranks the top feeds, permute randomly, use the clicks for data collection (provides randomness and helps in exploring more activities)

Model:
- logistic regression to work well with sparse features
- use distributed learning: Logistic Regression in Spark
- fully connected layers with the Sigmoid activation function applied to the final layer
- CTR is usually very small (less than 1%) —> we would need to resample the training data set to make the data less imbalanced
- split data into training and validation for evaluation. Data until time to t for training the model, data from time t+1 for testing, reorder ranking based on our model during inference. Total match = total clicks

**High-level system design**

Calculations:
- 30 million MAU
- user visits 10 times per month
- user sees 40 activities per visit
- total = 120 billion observations or samples
- if CTR is 1% for 1 month —> 1 billion positive labels, 110 billion negative labels
- storage: if each row takes 500 bytes to store, 120 billion rows will take: 60 Terabytes. To save costs we can keep the last 6 months or 1 year of data in the data lake and archive old data in cold storage

Feature store is feature value storage. Example: MySQL, Cluster, Redis, DynamoDB. Item store stores all activities generated by users. 

![IMG_6E8283D4DB8A-1](https://github.com/bsamanvitha/learning-journal/assets/6962922/87a43318-3e34-4463-95f2-c55596e35a29)

Flow:
- Client sends feed request to Application Server
- Application Server sends feed request to Feed Retrieval Service
- Feed Retrieval Service selects most relevant feeds from Item Store
- Feed Retrieval Service sends feed ranks request to Feed Ranking Service
- Feed Ranking Service gets the latest ML model, gets the right features from Feature Store
- Feed Ranking Service scores each feed and returns to Feed Retrieval Service and Application Server. Application server sorts feeds by rankings and return to client

**Scaling**
- Scale out the Feed Service module
- Scale out the Application Server, put the load balancer in front of the Application Server


